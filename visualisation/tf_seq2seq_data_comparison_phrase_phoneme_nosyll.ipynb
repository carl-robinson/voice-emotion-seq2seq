{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/Users/robinson/Dropbox/anasynth/_code', '/Users/robinson/Dropbox/anasynth/_code/as_pysrc', '/Users/robinson/Dropbox/anasynth/_code/tf_seq2seq', '/u/formes/share/packages/anaconda3/envs/DeepLearning/lib/python36.zip', '/u/formes/share/packages/anaconda3/envs/DeepLearning/lib/python3.6', '/u/formes/share/packages/anaconda3/envs/DeepLearning/lib/python3.6/lib-dynload', '/Users/robinson/Dropbox/anasynth/_code/anaconda/lib/python3.6/site-packages', '/Users/robinson/Dropbox/anasynth/_code/seq2seq', '/Users/robinson/Dropbox/anasynth/_code/anaconda/lib/python3.6/site-packages/as_pysrc_utils_poly-0.2-py3.6-macosx-10.7-x86_64.egg', '/Users/robinson/Dropbox/anasynth/_code/anaconda/lib/python3.6/site-packages/as_pysrc_utils_levinson-0.1-py3.6-macosx-10.7-x86_64.egg', '/Users/robinson/Dropbox/anasynth/_code/anaconda/lib/python3.6/site-packages/utils_bspline-1.0.0-py3.6-macosx-10.7-x86_64.egg', '/Users/robinson/Dropbox/anasynth/_code/anaconda/lib/python3.6/site-packages/opt_congrad_sc_c-1.2.2-py3.6-macosx-10.7-x86_64.egg', '/Users/robinson/Dropbox/anasynth/_code/anaconda/lib/python3.6/site-packages/dtw_c-1.1.0-py3.6-macosx-10.7-x86_64.egg', '/Users/robinson/Dropbox/anasynth/_code/anaconda/lib/python3.6/site-packages/ar_dap_conjugate_gradient_optimization_support-1.0.1-py3.6-macosx-10.7-x86_64.egg', '/Users/robinson/Dropbox/anasynth/_code/anaconda/lib/python3.6/site-packages/sig_proc_estim_harmonics-1.0.0-py3.6-macosx-10.7-x86_64.egg', '/u/formes/share/packages/anaconda3/envs/DeepLearning/lib/python3.6/site-packages', '/u/formes/share/packages/anaconda3/envs/DeepLearning/lib/python3.6/site-packages/aeosa', '/Applications/PyCharm.app/Contents/helpers/pycharm_matplotlib_backend', '/u/formes/share/packages/anaconda3/envs/DeepLearning/lib/python3.6/site-packages/IPython/extensions', '/Users/robinson/.ipython']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import numpy as np\n",
    "from scipy.io import wavfile, loadmat\n",
    "import os\n",
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where phonemes are kept, as per phon_input_directory_path\n",
    "dirr = '/Users/robinson/Downloads/data/pred/20180902_171045_col8_cond_i1to5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for each phrase, get source and predicted f0 for all syllables and assemble into one sequence, along with unvoiced # \n",
    "parts, and output into separate text files for us in the following code block \n",
    "'''\n",
    "\n",
    "# path to source F0 CSV input files directory\n",
    "csv_input_directory_path = '/Users/robinson/Dropbox/anasynth/_data/emoVC/Olivia2006/f0_raw_phoneme'\n",
    "# Olivia2006.e01.p01.i00.s01_s e.csv\n",
    "csv_input_file_extension = '.csv'\n",
    "\n",
    "# path to predicted F0 CSV input files directory\n",
    "phon_input_directory_path = '/Users/robinson/Downloads/data/pred/' + dirr + '/phonemes'\n",
    "# Olivia2006.e01.p01.i00.s01_s e1.csv\n",
    "phon_input_file_extension = '.csv'\n",
    "\n",
    "# path to MAT input files directory\n",
    "mat_input_directory_path = '/Users/robinson/Dropbox/anasynth/_data/emoVC/Olivia2006'\n",
    "# Olivia2006.e01.p01.i00.mat\n",
    "mat_input_file_extension = '.mat'\n",
    "\n",
    "# path to WAV input files directory\n",
    "raw_input_directory_path = '/Users/robinson/Downloads/data/Olivia2006/Olivia2006_AUDIO/'\n",
    "# Olivia2006.e01.p01.i00.1.wav\n",
    "raw_input_file_extension = '.wav'\n",
    "\n",
    "# define input file root - common to all filetypes\n",
    "input_file_root = 'Olivia2006'\n",
    "\n",
    "# define output directory and files\n",
    "output_directory = os.path.join(raw_input_directory_path, 'f0compare')\n",
    "if not os.path.exists(output_directory):\n",
    "    os.mkdir(output_directory)\n",
    "    \n",
    "# open test_log.txt and split into list of lines\n",
    "f_test_log = open(os.path.join(csv_input_directory_path, 'out', 'test_log.txt'), 'r')\n",
    "# f_test_log = open(os.path.join('/Users/robinson/Downloads/data/pred/20180628_151243', 'test_log.txt'), 'r')  # debug\n",
    "test_log = f_test_log.read().split('\\n')\n",
    "\n",
    "# define phrase range\n",
    "phrase_from = 1\n",
    "phrase_to = 10  #10\n",
    "# define source and target emotion ranges\n",
    "source_emotion_from = 1\n",
    "source_emotion_to = 8  #8\n",
    "# define source and target intensity ranges\n",
    "source_intensity_from = 0\n",
    "source_intensity_to = 0\n",
    "\n",
    "# set sample rate \n",
    "step_s = 0.005 # 5ms, which I assume is what was used to sample the file\n",
    "\n",
    "# file counter \n",
    "i = 0\n",
    "\n",
    "# Turn interactive plotting off\n",
    "plt.ioff()\n",
    "\n",
    "# lists to store all syllables and phonemes in all files\n",
    "all_phonemes = []\n",
    "\n",
    "# for each wavfile that we want to treat..\n",
    "# for each phrase\n",
    "for p in range(phrase_from, phrase_to + 1):\n",
    "    # for each source emotion\n",
    "    for e_s in range(source_emotion_from, source_emotion_to + 1):\n",
    "        # for each source intensity\n",
    "        for i_s in range(source_intensity_from, source_intensity_to + 1):\n",
    "            # build the source file path\n",
    "            filename_base = ''.join([input_file_root, \n",
    "                                        '.e', format(e_s, '02d'),\n",
    "                                        '.p', format(p, '02d'),\n",
    "                                        '.i', format(i_s, '02d')])\n",
    "            \n",
    "            # open the mat file \n",
    "            mat_filename = ''.join([filename_base, mat_input_file_extension])\n",
    "            mat_filepath = os.path.join(mat_input_directory_path, mat_filename)\n",
    "            mat_dict = loadmat(mat_filepath)\n",
    "\n",
    "            syll_label = mat_dict['syll_label']\n",
    "            syll_label = syll_label.reshape((syll_label.shape[1],))        \n",
    "            # print(syll_label.shape)\n",
    "            # print(syll_label)\n",
    "            # reshape this to 2d, to preserve start/end relationship\n",
    "            # syll_time.shape (2, 11)\n",
    "            # I want syll_time.shape (11, 2) BUT with the start and end times in different 'columns' - just transpose!\n",
    "            syll_time = mat_dict['syll_time']\n",
    "            # print('syll_time.shape', syll_time.shape)\n",
    "            syll_time = syll_time.T\n",
    "\n",
    "            # get list of phonemes\n",
    "            phon_label = mat_dict['phone_label']\n",
    "            phon_label = phon_label.reshape((phon_label.shape[1],))\n",
    "            # get list of phoneme start/end times\n",
    "            phon_time = mat_dict['phone_time']\n",
    "            # print(phon_time.shape)\n",
    "            # print(phon_time)\n",
    "            # phon_time = phon_time.reshape((phon_time.shape[1], phon_time.shape[0]))  # wrong!\n",
    "            phon_time = phon_time.T # much better\n",
    "            \n",
    "            # make list of true/false to indicate vowels(true)/nonvowel(false)\n",
    "            vowel_phonemes = ['e~', '9~', 'a~', 'o~', 'i', 'e', 'E', 'a', 'A', 'O', 'o', 'u', 'y', '2', '9', '@']\n",
    "            # [a if C else b for i in items]\n",
    "            vowels = [True if phon[0] in vowel_phonemes else False for i, phon in enumerate(phon_label)]\n",
    "            # print('vowels ', vowels)\n",
    "            \n",
    "            # create list to hold sequence of voiced and unvoiced f0 contour values\n",
    "            # all_contours = []\n",
    "            \n",
    "            # create new figure for this phrase\n",
    "            fig = plt.figure(figsize=(16, 8))\n",
    "            plt.title(filename_base)\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('Freq (Hz)')\n",
    "            # plt.xlim(0, 800)\n",
    "            plt.ylim(-20, 700)   \n",
    "            \n",
    "            values = np.arange(phon_label.shape[0]).tolist()\n",
    "            # print(values)\n",
    "            # print(syll_label.shape[0])\n",
    "            jet = plt.get_cmap('Dark2')\n",
    "            cNorm = colors.Normalize(vmin=0, vmax=values[-1])\n",
    "            scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)            \n",
    "            \n",
    "            start_source = 0\n",
    "            start_target = 0\n",
    "            \n",
    "            colour_counter = 0\n",
    "            # voiced_syll_counter = 0\n",
    "            \n",
    "            # dict to hold phoneme identifiers for this file (phrase)\n",
    "            phon_dict = {}            \n",
    "\n",
    "            # for each syll in syll_label\n",
    "            for i, syll in enumerate(syll_label):\n",
    "    \n",
    "                # if syll_label doesn't contain a '#' in it\n",
    "                if '#' not in syll[0]:\n",
    "                    # print(syll[0])\n",
    "                    \n",
    "                    # get syll_time start and end times\n",
    "                    # print('i = ', i)\n",
    "                    syll_start_time = syll_time[i, 0]\n",
    "                    syll_end_time = syll_time[i, 1]                    \n",
    "            \n",
    "                    phone_id_list = []\n",
    "                    # for each phone label in phone_label (this mat file)\n",
    "                    for j, label in enumerate(phon_label):\n",
    "                        # get start/end times from phone_time\n",
    "                        phone_start_time = phon_time[j, 0]\n",
    "                        phone_end_time = phon_time[j, 1]\n",
    "                        # if start time => syll_start_time AND end time <= syll_end_time then this phoneme is in the syllable\n",
    "                        if phone_start_time >= syll_start_time and phone_end_time <= syll_end_time:\n",
    "                            # add phoneme label id to a list (to use to reference label and start/end times)\n",
    "                            phone_id_list.append(j)            \n",
    "                \n",
    "    \n",
    "                    # iterate through phonemes of this syllable\n",
    "                    for k in phone_id_list:\n",
    "                        # for all_phon_counter, phon in enumerate(phon_label):\n",
    "\n",
    "                        # check if phone_label[k][0] is in phon_dict\n",
    "                        # if so, incremement the value and save value into phon_incval\n",
    "                        if phon_label[k][0] in phon_dict:\n",
    "                            phon_dict[phon_label[k][0]] = phon_dict[phon_label[k][0]] + 1\n",
    "                            phon_incval = phon_dict[phon_label[k][0]]\n",
    "                            # print('IN')\n",
    "                        # if not, add it with value 1 and save value into phon_incval\n",
    "                        else:    \n",
    "                            phon_dict[phon_label[k][0]] = 1\n",
    "                            phon_incval = phon_dict[phon_label[k][0]]\n",
    "                            # print('NOT')\n",
    "                        # append the phone_label[k][0] + phon_incval to all_phonemes \n",
    "                        # print('phone_label[k][0] = ', phone_label[k][0])\n",
    "                        # print('phon_label = {}'.format(phone_label[k][0] + str(phon_incval)))\n",
    "                        all_phonemes.append(phon_label[k][0] + str(phon_incval))                        \n",
    "                        \n",
    "                        # print('******** SYL ********')\n",
    "                        # build the filename of the syllable\n",
    "                        filename_phon = ''.join([filename_base, '_',\n",
    "                                                 phon_label[k][0], str(phon_incval), \n",
    "                                                 csv_input_file_extension])                        \n",
    "                        # build the source file path\n",
    "                        source_file_path = os.path.join(csv_input_directory_path, filename_phon)\n",
    "                        # print(source_file_path)\n",
    "                        \n",
    "                        # if phoneme is not a vowel, or if phon file is not in test_log.txt (i.e. it's missing or empty), \n",
    "                        # get the length of the nonvowel phoneme and add zeroes to all_contours list\n",
    "                        # if not vowels[all_phon_counter] or filename_phon not in test_log:\n",
    "                        if phon_label[k][0] not in vowel_phonemes:\n",
    "                            # print('!!! non-vowel')\n",
    "                            time = phon_time[k, 1] - phon_time[k, 0]\n",
    "                            # print('time ', time)\n",
    "                            num_zeroes = int(time // step_s)\n",
    "                            # print('num_zeroes ', num_zeroes)\n",
    "                            contour_source = contour_target = [0 for _ in range(num_zeroes)]\n",
    "                        # if syllable is voiced, add its contents to the all_contours list\n",
    "                        else:\n",
    "                            # print('!!! vowel')\n",
    "                            \n",
    "                            replacement = ''\n",
    "                            with open(source_file_path) as f:\n",
    "                                s = f.read()\n",
    "                                s = s.replace('a', replacement)\n",
    "                                s = s.replace('b', replacement)\n",
    "                                s = s.replace('c', replacement)\n",
    "                            with open(source_file_path, 'w') as f:\n",
    "                                f.write(s)                         \n",
    "                            \n",
    "                            # load the source file and extract vars\n",
    "                            source_f0_raw = np.loadtxt(source_file_path, dtype='int')\n",
    "                            # iterate over the numpy array, adding items to the list\n",
    "                            contour_source = [source_f0_raw[x] for x in range(source_f0_raw.shape[0])]\n",
    "                            \n",
    "                            # build the target file path\n",
    "                            target_file_path = os.path.join(phon_input_directory_path, filename_phon)\n",
    "                            # load the target file and extract vars\n",
    "                            try:\n",
    "                                target_f0_raw = np.loadtxt(target_file_path, dtype='int')\n",
    "                            except:\n",
    "                                continue\n",
    "                            # iterate over the numpy array, adding items to the list\n",
    "                            contour_target = [target_f0_raw[x] for x in range(target_f0_raw.shape[0])]\n",
    "                            # # increment counter\n",
    "                            # voiced_syll_counter += 1\n",
    "                        \n",
    "                        # if a voiced phoneme, plot as a colour\n",
    "                        if vowels[k]:\n",
    "                            colorVal = scalarMap.to_rgba(values[k])\n",
    "                        # if unvoiced, plot as grey (to show not converted\n",
    "                        else:\n",
    "                            # print(colors.to_rgba('grey'))\n",
    "                            colorVal = colors.to_rgba('black')\n",
    "                        \n",
    "                        # plot the source phoneme\n",
    "                        plt.plot(range(start_source, start_source + len(contour_source)), contour_source, color=colorVal, \n",
    "                                 alpha=0.7, linewidth=3, label='source')\n",
    "                        start_source += len(contour_source)\n",
    "                        \n",
    "                        plt.plot(range(start_target, start_target + len(contour_target)), contour_target, color=colorVal, \n",
    "                                 alpha=0.7, linestyle=':', linewidth=3, label='predicted')\n",
    "                        start_target += len(contour_target)    \n",
    "            \n",
    "            # add legend to each figure\n",
    "            # plt.legend()\n",
    "            plt.tight_layout()\n",
    "            fig.savefig(os.path.join(output_directory, filename_base + '.png'))\n",
    "            # close the fig so it never gets displayed - used with plt.ioff()\n",
    "            plt.close(fig)\n",
    "            # increment counters\n",
    "            i += 1\n",
    "            \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
